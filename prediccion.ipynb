{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\leand\\Desktop\\Data Science (Henry)\\Proyectos\\Hackathon\\Housing Dreams\\houses_test_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropeamos esta columna, que practicamente no tiene valores\n",
    "\n",
    "data.drop(columns = 'Alley', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropeamos esta columna también, ya que casi la mitad no tiene registros y además la información que brinda es intrascendente\n",
    "\n",
    "data.drop(columns = 'FireplaceQu', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = ['PoolQC', 'MiscFeature', 'Fence', 'Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'LotFrontage': data.LotFrontage.mean()}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MasVnrType***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'MasVnrType': 'None'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MasVnrArea***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'MasVnrArea': data.MasVnrArea.mean()}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas asociadas con Basement : ***BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos con NA\n",
    "\n",
    "data.fillna({'BsmtQual': 'NA'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos con NA\n",
    "\n",
    "data.fillna({'BsmtQual' : 'NA', 'BsmtCond': 'NA', 'BsmtCond' : 'NA', 'BsmtExposure': 'NA', 'BsmtFinType1' : 'NA', 'BsmtFinType2' : 'NA' }, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Electrical***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'Electrical' : 'SBrkr'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnas asociadas con garage : ***'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna({'GarageType' : 'NA', 'GarageFinish' : 'NA', 'GarageQual': 'NA', 'GarageCond' : 'NA'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Años en que fue construído el garage\n",
    "\n",
    "data.fillna({'GarageYrBlt' : 0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a entero\n",
    "\n",
    "data.GarageYrBlt = data.GarageYrBlt.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, nos quedamos con las variables que son mejores predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos las correlaciones respecto al precio\n",
    "\n",
    "corr = data.corr()\n",
    "\n",
    "#Nos quedamos con las columnas que tienen una correlación respecto al precio mayor a 0.3 o menor a -0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción de la dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A continuación, de las columnas cuantitativas nos quedaremos solamente con las que tienen una correlación con SalePrice (Pearson, Kendall o Spearman) mayores a 0.3 o menores a -0.3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_columns = ['LotFrontage',\n",
    " 'OverallQual',\n",
    " 'YearBuilt',\n",
    " 'YearRemodAdd',\n",
    " 'MasVnrArea',\n",
    " 'BsmtFinSF1',\n",
    " 'TotalBsmtSF',\n",
    " '1stFlrSF',\n",
    " '2ndFlrSF',\n",
    " 'GrLivArea',\n",
    " 'FullBath',\n",
    " 'TotRmsAbvGrd',\n",
    " 'Fireplaces',\n",
    " 'GarageCars',\n",
    " 'GarageArea',\n",
    " 'WoodDeckSF',\n",
    " 'OpenPorchSF',\n",
    " 'LotArea',\n",
    " 'HalfBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cuanti = pd.DataFrame(data, columns= lista_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luego, incorporamos las columnas categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que los modelos que instanciemos puedan utilizar las variables categóricas, es necesario pasarlas a numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista con todas las variables que son categóricas\n",
    "\n",
    "variables_cat = list(data.dtypes[data.dtypes == object].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos el índice para poder mergear posteriormente \n",
    "\n",
    "data['index'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = data[variables_cat].copy()\n",
    "\n",
    "data_encoded['index'] = data_encoded.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos todas las columnas categóricas en cuantitativas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for i in variables_cat:\n",
    "    le = LabelEncoder()\n",
    "    data_encoded[i] = le.fit_transform(data_encoded[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos todas las columnas categóricas en cuantitativas\n",
    "\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#for i in variables_cat:\n",
    "\n",
    "   # data_encoded_i = data[[i]]\n",
    "   # one = OneHotEncoder(handle_unknown = 'ignore')\n",
    "   # column = pd.DataFrame(one.fit_transform(data_encoded_i).toarray())\n",
    "   # column['index'] = column.index\n",
    "   # data_encoded = pd.merge(data_encoded, column, on = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CUIDADO, SOLO PARA ONE HOT ENCODER\n",
    "# \n",
    "#  Quitamos las variables categóricas, que ya fueron transformadas, de nuestro dataset\n",
    "\n",
    "#data_encoded.drop(columns= variables_cat, inplace= True ) # ESTO PARA ONE HOT ENCODER NOMÁS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteamos el índice como columna para poder mergear correctamente\n",
    "\n",
    "data_cuanti['index'] = data_cuanti.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSZoning  Street  LotShape  LandContour  Utilities  LotConfig  \\\n",
       "0            2       1         3            3          0          4   \n",
       "1            3       1         0            3          0          0   \n",
       "2            3       1         0            3          0          4   \n",
       "3            3       1         0            3          0          4   \n",
       "4            3       1         0            1          0          4   \n",
       "...        ...     ...       ...          ...        ...        ...   \n",
       "1454         4       1         3            3          0          4   \n",
       "1455         4       1         3            3          0          4   \n",
       "1456         3       1         3            3          0          4   \n",
       "1457         3       1         3            3          0          4   \n",
       "1458         3       1         3            3          0          4   \n",
       "\n",
       "      LandSlope  Neighborhood  Condition1  Condition2  ...  KitchenQual  \\\n",
       "0             0            12           1           2  ...            3   \n",
       "1             0            12           2           2  ...            2   \n",
       "2             0             8           2           2  ...            3   \n",
       "3             0             8           2           2  ...            2   \n",
       "4             0            22           2           2  ...            2   \n",
       "...         ...           ...         ...         ...  ...          ...   \n",
       "1454          0            10           2           2  ...            3   \n",
       "1455          0            10           2           2  ...            3   \n",
       "1456          0            11           2           2  ...            3   \n",
       "1457          0            11           2           2  ...            3   \n",
       "1458          1            11           2           2  ...            3   \n",
       "\n",
       "      Functional  GarageType  GarageFinish  GarageQual  GarageCond  \\\n",
       "0              6           1             3           4           5   \n",
       "1              6           1             3           4           5   \n",
       "2              6           1             0           4           5   \n",
       "3              6           1             0           4           5   \n",
       "4              6           1             2           4           5   \n",
       "...          ...         ...           ...         ...         ...   \n",
       "1454           6           6             1           2           3   \n",
       "1455           6           4             3           4           5   \n",
       "1456           6           5             3           4           5   \n",
       "1457           6           6             1           2           3   \n",
       "1458           6           1             0           4           5   \n",
       "\n",
       "      PavedDrive  SaleType  SaleCondition  index  \n",
       "0              2         8              4      0  \n",
       "1              2         8              4      1  \n",
       "2              2         8              4      2  \n",
       "3              2         8              4      3  \n",
       "4              2         8              4      4  \n",
       "...          ...       ...            ...    ...  \n",
       "1454           2         8              4   1454  \n",
       "1455           2         8              0   1455  \n",
       "1456           2         8              0   1456  \n",
       "1457           2         8              4   1457  \n",
       "1458           2         8              4   1458  \n",
       "\n",
       "[1459 rows x 39 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos en un solo dataset las variables que separamos en un principio (con correlación mayor a 0.3) y  las que acabamos de convertir\n",
    "\n",
    "data = pd.merge(data_cuanti, data_encoded, on = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya no necesitamos la columna 'index' que fuimos creando para realizar los Merge correctamente\n",
    "\n",
    "data.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escalado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>...</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>1629</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>1604</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>21.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>1092</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>21.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>1092</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>160.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>1224</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>62.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>970</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>74.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage  OverallQual  YearBuilt  YearRemodAdd  MasVnrArea  \\\n",
       "0            80.0            5       1961          1961         0.0   \n",
       "1            81.0            6       1958          1958       108.0   \n",
       "2            74.0            5       1997          1998         0.0   \n",
       "3            78.0            6       1998          1998        20.0   \n",
       "4            43.0            8       1992          1992         0.0   \n",
       "...           ...          ...        ...           ...         ...   \n",
       "1454         21.0            4       1970          1970         0.0   \n",
       "1455         21.0            4       1970          1970         0.0   \n",
       "1456        160.0            5       1960          1996         0.0   \n",
       "1457         62.0            5       1992          1992         0.0   \n",
       "1458         74.0            7       1993          1994        94.0   \n",
       "\n",
       "      BsmtFinSF1  TotalBsmtSF  1stFlrSF  2ndFlrSF  GrLivArea  ...  Electrical  \\\n",
       "0          468.0        882.0       896         0        896  ...           3   \n",
       "1          923.0       1329.0      1329         0       1329  ...           3   \n",
       "2          791.0        928.0       928       701       1629  ...           3   \n",
       "3          602.0        926.0       926       678       1604  ...           3   \n",
       "4          263.0       1280.0      1280         0       1280  ...           3   \n",
       "...          ...          ...       ...       ...        ...  ...         ...   \n",
       "1454         0.0        546.0       546       546       1092  ...           3   \n",
       "1455       252.0        546.0       546       546       1092  ...           3   \n",
       "1456      1224.0       1224.0      1224         0       1224  ...           3   \n",
       "1457       337.0        912.0       970         0        970  ...           3   \n",
       "1458       758.0        996.0       996      1004       2000  ...           3   \n",
       "\n",
       "      KitchenQual  Functional  GarageType  GarageFinish  GarageQual  \\\n",
       "0               3           6           1             3           4   \n",
       "1               2           6           1             3           4   \n",
       "2               3           6           1             0           4   \n",
       "3               2           6           1             0           4   \n",
       "4               2           6           1             2           4   \n",
       "...           ...         ...         ...           ...         ...   \n",
       "1454            3           6           6             1           2   \n",
       "1455            3           6           4             3           4   \n",
       "1456            3           6           5             3           4   \n",
       "1457            3           6           6             1           2   \n",
       "1458            3           6           1             0           4   \n",
       "\n",
       "      GarageCond  PavedDrive  SaleType  SaleCondition  \n",
       "0              5           2         8              4  \n",
       "1              5           2         8              4  \n",
       "2              5           2         8              4  \n",
       "3              5           2         8              4  \n",
       "4              5           2         8              4  \n",
       "...          ...         ...       ...            ...  \n",
       "1454           3           2         8              4  \n",
       "1455           5           2         8              0  \n",
       "1456           5           2         8              0  \n",
       "1457           3           2         8              4  \n",
       "1458           5           2         8              4  \n",
       "\n",
       "[1459 rows x 57 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>...</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>1629</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>1604</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  OverallQual  YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  \\\n",
       "0         80.0            5       1961          1961         0.0       468.0   \n",
       "1         81.0            6       1958          1958       108.0       923.0   \n",
       "2         74.0            5       1997          1998         0.0       791.0   \n",
       "3         78.0            6       1998          1998        20.0       602.0   \n",
       "4         43.0            8       1992          1992         0.0       263.0   \n",
       "\n",
       "   TotalBsmtSF  1stFlrSF  2ndFlrSF  GrLivArea  ...  Electrical  KitchenQual  \\\n",
       "0        882.0       896         0        896  ...           3            3   \n",
       "1       1329.0      1329         0       1329  ...           3            2   \n",
       "2        928.0       928       701       1629  ...           3            3   \n",
       "3        926.0       926       678       1604  ...           3            2   \n",
       "4       1280.0      1280         0       1280  ...           3            2   \n",
       "\n",
       "   Functional  GarageType  GarageFinish  GarageQual  GarageCond  PavedDrive  \\\n",
       "0           6           1             3           4           5           2   \n",
       "1           6           1             3           4           5           2   \n",
       "2           6           1             0           4           5           2   \n",
       "3           6           1             0           4           5           2   \n",
       "4           6           1             2           4           5           2   \n",
       "\n",
       "   SaleType  SaleCondition  \n",
       "0         8              4  \n",
       "1         8              4  \n",
       "2         8              4  \n",
       "3         8              4  \n",
       "4         8              4  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cuanti = data[lista_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler ()\n",
    "\n",
    "#Para estandarizar, debo quedarme solamente con las variables de entrada que contienen atributos cuantitativos. \n",
    "# A su vez, la variable de salida no debemos escalarla\n",
    "\n",
    "\n",
    "#data_scaled = data_cuanti.drop(columns = 'SalePrice')\n",
    "\n",
    "data_scaled = pd.DataFrame(scaler.fit_transform(data_cuanti), columns = data_cuanti.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>HalfBath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555587</td>\n",
       "      <td>-0.751101</td>\n",
       "      <td>-0.340945</td>\n",
       "      <td>-1.072885</td>\n",
       "      <td>-0.570108</td>\n",
       "      <td>0.063273</td>\n",
       "      <td>-0.370681</td>\n",
       "      <td>-0.654561</td>\n",
       "      <td>-0.775254</td>\n",
       "      <td>-1.215588</td>\n",
       "      <td>-1.02872</td>\n",
       "      <td>-0.918335</td>\n",
       "      <td>-0.898055</td>\n",
       "      <td>-0.987674</td>\n",
       "      <td>1.185538</td>\n",
       "      <td>0.366678</td>\n",
       "      <td>-0.701628</td>\n",
       "      <td>0.363929</td>\n",
       "      <td>-0.751040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.604239</td>\n",
       "      <td>-0.054877</td>\n",
       "      <td>-0.439695</td>\n",
       "      <td>-1.214908</td>\n",
       "      <td>0.041273</td>\n",
       "      <td>1.063027</td>\n",
       "      <td>0.638925</td>\n",
       "      <td>0.433298</td>\n",
       "      <td>-0.775254</td>\n",
       "      <td>-0.323539</td>\n",
       "      <td>-1.02872</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.898055</td>\n",
       "      <td>-0.987674</td>\n",
       "      <td>-0.740959</td>\n",
       "      <td>2.347867</td>\n",
       "      <td>-0.178826</td>\n",
       "      <td>0.897861</td>\n",
       "      <td>1.237648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  OverallQual  YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  \\\n",
       "0     0.555587    -0.751101  -0.340945     -1.072885   -0.570108    0.063273   \n",
       "1     0.604239    -0.054877  -0.439695     -1.214908    0.041273    1.063027   \n",
       "\n",
       "   TotalBsmtSF  1stFlrSF  2ndFlrSF  GrLivArea  FullBath  TotRmsAbvGrd  \\\n",
       "0    -0.370681 -0.654561 -0.775254  -1.215588  -1.02872     -0.918335   \n",
       "1     0.638925  0.433298 -0.775254  -0.323539  -1.02872     -0.255371   \n",
       "\n",
       "   Fireplaces  GarageCars  GarageArea  WoodDeckSF  OpenPorchSF   LotArea  \\\n",
       "0   -0.898055   -0.987674    1.185538    0.366678    -0.701628  0.363929   \n",
       "1   -0.898055   -0.987674   -0.740959    2.347867    -0.178826  0.897861   \n",
       "\n",
       "   HalfBath  \n",
       "0 -0.751040  \n",
       "1  1.237648  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a incoporar al dataset el atributo de salida 'y' así como las columnas categóricas codificadas\n",
    "\n",
    "# Me quedo con las columnas de data que empiezan en la nùmero 20, ya que las anteriores son las cuantitativas sin escalar\n",
    "\n",
    "# A su vez, debo volver a traer la columna SalePrice que quedó mezclada entre todas las primeras 20 que son cuantitativas\n",
    "\n",
    "data_test = data_scaled.join(data.iloc[:,19:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>...</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [LotFrontage, OverallQual, YearBuilt, YearRemodAdd, MasVnrArea, BsmtFinSF1, TotalBsmtSF, 1stFlrSF, 2ndFlrSF, GrLivArea, FullBath, TotRmsAbvGrd, Fireplaces, GarageCars, GarageArea, WoodDeckSF, OpenPorchSF, LotArea, HalfBath, MSZoning, Street, LotShape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, Heating, HeatingQC, CentralAir, Electrical, KitchenQual, Functional, GarageType, GarageFinish, GarageQual, GarageCond, PavedDrive, SaleType, SaleCondition]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 57 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[pd.isnull(data_test).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.fillna({'BsmtFinSF1' : data_test.BsmtFinSF1.mean(), 'TotalBsmtSF': data_test.TotalBsmtSF.mean(), 'GarageArea' : data_test.GarageArea.mean(), 'GarageCars': data_test.GarageCars.mean()}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = pd.read_csv('data_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos los atributos predictores y la variable a predecir\n",
    "\n",
    "X = data_scaled.drop(\"SalePrice\", axis=1)\n",
    "y = data_scaled.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en un subset de entrenamiento y otro de testeo\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***En esta instancia, probamos un Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "randomf = RandomForestRegressor()\n",
    "\n",
    "randomf_scores = cross_val_score(randomf, X, y, cv=5)\n",
    "randomf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86713219 0.8430283  0.88638489 0.8828921  0.84337714]\n",
      "Precisión para Random Forest: 0.86 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "print(randomf_scores)\n",
    "print(\"Precisión para Random Forest: %0.2f (+/- %0.2f)\" % (randomf_scores.mean(), randomf_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_log_error en Train es: 0.060136424210371096\n",
      "mean_squared_log_error en Test es: 0.14188759176465426\n",
      "La precisión del modelo de Random Forest en train es: 0.9780492857119409\n",
      "La precisión del modelo de Random Forest en test es: 0.904375523120529\n"
     ]
    }
   ],
   "source": [
    "# CON LABEL ENCODER EL ERROR DA 0.02\n",
    "\n",
    "rmse_train = (mean_squared_log_error(y_train, y_train_pred3, squared= False))\n",
    "rmse_test = (mean_squared_log_error(y_test, y_test_pred3, squared= False))\n",
    "print(f'mean_squared_log_error en Train es: {rmse_train}')\n",
    "print(f'mean_squared_log_error en Test es: {rmse_test}')\n",
    "print('La precisión del modelo de Random Forest en train es:', randomf.score (X_train,y_train))\n",
    "print('La precisión del modelo de Random Forest en test es:', randomf.score (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred5 = randomf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([124439.5 , 156224.5 , 190521.87, ..., 152236.  , 123545.71,\n",
       "       233933.38])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Valor predicho (US$)')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "plt.scatter(y_test,y_test_pred3, s =2)\n",
    "plt.xlabel('Valor real (US$)', fontweight = \"black\", fontsize = 12)\n",
    "plt.ylabel('Valor predicho (US$)', fontweight = \"black\", fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leand\\Desktop\\Data Science (Henry)\\Proyectos\\Hackathon\\Housing Dreams\\prediccion.ipynb Celda 77\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leand/Desktop/Data%20Science%20%28Henry%29/Proyectos/Hackathon/Housing%20Dreams/prediccion.ipynb#ch0000111?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m GridSearchCV(randomf, param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/leand/Desktop/Data%20Science%20%28Henry%29/Proyectos/Hackathon/Housing%20Dreams/prediccion.ipynb#ch0000111?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    454\u001b[0m )(\n\u001b[0;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    456\u001b[0m         t,\n\u001b[0;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    458\u001b[0m         X,\n\u001b[0;32m    459\u001b[0m         y,\n\u001b[0;32m    460\u001b[0m         sample_weight,\n\u001b[0;32m    461\u001b[0m         i,\n\u001b[0;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    468\u001b[0m )\n\u001b[0;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1316\u001b[0m         X,\n\u001b[0;32m   1317\u001b[0m         y,\n\u001b[0;32m   1318\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1319\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1320\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[0;32m   1321\u001b[0m     )\n\u001b[0;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(randomf, param_grid, cv=5)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_features': 6, 'n_estimators': 167, 'n_jobs': -1, 'random_state': 42}\n",
      "Mejor Score: 0.8022192067603328\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039804</td>\n",
       "      <td>0.002139</td>\n",
       "      <td>0.020596</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 20, 'n_job...</td>\n",
       "      <td>0.759520</td>\n",
       "      <td>0.827697</td>\n",
       "      <td>0.768500</td>\n",
       "      <td>0.829069</td>\n",
       "      <td>0.755201</td>\n",
       "      <td>0.787997</td>\n",
       "      <td>0.033255</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069009</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>0.015993</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 50, 'n_job...</td>\n",
       "      <td>0.747206</td>\n",
       "      <td>0.830561</td>\n",
       "      <td>0.744601</td>\n",
       "      <td>0.816521</td>\n",
       "      <td>0.760813</td>\n",
       "      <td>0.779941</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111984</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.019785</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 75, 'n_job...</td>\n",
       "      <td>0.751464</td>\n",
       "      <td>0.831765</td>\n",
       "      <td>0.749651</td>\n",
       "      <td>0.815494</td>\n",
       "      <td>0.756693</td>\n",
       "      <td>0.781013</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139001</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 107, 'n_jo...</td>\n",
       "      <td>0.755508</td>\n",
       "      <td>0.831706</td>\n",
       "      <td>0.746286</td>\n",
       "      <td>0.804759</td>\n",
       "      <td>0.766386</td>\n",
       "      <td>0.780929</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.136607</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 127, 'n_jo...</td>\n",
       "      <td>0.756716</td>\n",
       "      <td>0.832923</td>\n",
       "      <td>0.747744</td>\n",
       "      <td>0.806663</td>\n",
       "      <td>0.766394</td>\n",
       "      <td>0.782088</td>\n",
       "      <td>0.032427</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.170410</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.029393</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 147, 'n_jo...</td>\n",
       "      <td>0.757940</td>\n",
       "      <td>0.829023</td>\n",
       "      <td>0.749053</td>\n",
       "      <td>0.805275</td>\n",
       "      <td>0.759404</td>\n",
       "      <td>0.780139</td>\n",
       "      <td>0.031339</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.202728</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.033383</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 167, 'n_jo...</td>\n",
       "      <td>0.758432</td>\n",
       "      <td>0.831361</td>\n",
       "      <td>0.746100</td>\n",
       "      <td>0.804111</td>\n",
       "      <td>0.761363</td>\n",
       "      <td>0.780273</td>\n",
       "      <td>0.032189</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.166810</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.033990</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 187, 'n_jo...</td>\n",
       "      <td>0.758640</td>\n",
       "      <td>0.831192</td>\n",
       "      <td>0.746991</td>\n",
       "      <td>0.807344</td>\n",
       "      <td>0.763413</td>\n",
       "      <td>0.781516</td>\n",
       "      <td>0.032180</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.237019</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.038992</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 220, 'n_jo...</td>\n",
       "      <td>0.759408</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.747836</td>\n",
       "      <td>0.810485</td>\n",
       "      <td>0.769562</td>\n",
       "      <td>0.784399</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.039810</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.011790</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 20, 'n_job...</td>\n",
       "      <td>0.755101</td>\n",
       "      <td>0.823724</td>\n",
       "      <td>0.735637</td>\n",
       "      <td>0.814792</td>\n",
       "      <td>0.753147</td>\n",
       "      <td>0.776480</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.069007</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 50, 'n_job...</td>\n",
       "      <td>0.771708</td>\n",
       "      <td>0.842411</td>\n",
       "      <td>0.741675</td>\n",
       "      <td>0.813048</td>\n",
       "      <td>0.780490</td>\n",
       "      <td>0.789866</td>\n",
       "      <td>0.034752</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.120407</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>0.020194</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 75, 'n_job...</td>\n",
       "      <td>0.781878</td>\n",
       "      <td>0.843712</td>\n",
       "      <td>0.742379</td>\n",
       "      <td>0.815981</td>\n",
       "      <td>0.781579</td>\n",
       "      <td>0.793106</td>\n",
       "      <td>0.034399</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.137814</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 107, 'n_jo...</td>\n",
       "      <td>0.775777</td>\n",
       "      <td>0.844674</td>\n",
       "      <td>0.749808</td>\n",
       "      <td>0.817724</td>\n",
       "      <td>0.776350</td>\n",
       "      <td>0.792867</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.140422</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 127, 'n_jo...</td>\n",
       "      <td>0.771814</td>\n",
       "      <td>0.841988</td>\n",
       "      <td>0.747462</td>\n",
       "      <td>0.819544</td>\n",
       "      <td>0.766930</td>\n",
       "      <td>0.789548</td>\n",
       "      <td>0.035347</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.173627</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 147, 'n_jo...</td>\n",
       "      <td>0.773096</td>\n",
       "      <td>0.841828</td>\n",
       "      <td>0.746907</td>\n",
       "      <td>0.820341</td>\n",
       "      <td>0.770031</td>\n",
       "      <td>0.790441</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.211419</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.033191</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>5</td>\n",
       "      <td>167</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 167, 'n_jo...</td>\n",
       "      <td>0.768787</td>\n",
       "      <td>0.841319</td>\n",
       "      <td>0.751150</td>\n",
       "      <td>0.819941</td>\n",
       "      <td>0.768206</td>\n",
       "      <td>0.789881</td>\n",
       "      <td>0.034538</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.173633</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.035592</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 187, 'n_jo...</td>\n",
       "      <td>0.767931</td>\n",
       "      <td>0.842859</td>\n",
       "      <td>0.750304</td>\n",
       "      <td>0.820470</td>\n",
       "      <td>0.767157</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.035515</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.252068</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.041722</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 5, 'n_estimators': 220, 'n_jo...</td>\n",
       "      <td>0.771868</td>\n",
       "      <td>0.842996</td>\n",
       "      <td>0.748391</td>\n",
       "      <td>0.821888</td>\n",
       "      <td>0.766949</td>\n",
       "      <td>0.790418</td>\n",
       "      <td>0.035822</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.040604</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 20, 'n_job...</td>\n",
       "      <td>0.802169</td>\n",
       "      <td>0.846604</td>\n",
       "      <td>0.762614</td>\n",
       "      <td>0.822268</td>\n",
       "      <td>0.752982</td>\n",
       "      <td>0.797327</td>\n",
       "      <td>0.035342</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.069808</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 50, 'n_job...</td>\n",
       "      <td>0.782791</td>\n",
       "      <td>0.846356</td>\n",
       "      <td>0.770091</td>\n",
       "      <td>0.815693</td>\n",
       "      <td>0.777640</td>\n",
       "      <td>0.798514</td>\n",
       "      <td>0.028547</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.114324</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 75, 'n_job...</td>\n",
       "      <td>0.775715</td>\n",
       "      <td>0.843925</td>\n",
       "      <td>0.769760</td>\n",
       "      <td>0.823698</td>\n",
       "      <td>0.774360</td>\n",
       "      <td>0.797492</td>\n",
       "      <td>0.030401</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.139382</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 107, 'n_jo...</td>\n",
       "      <td>0.779693</td>\n",
       "      <td>0.851002</td>\n",
       "      <td>0.768600</td>\n",
       "      <td>0.826142</td>\n",
       "      <td>0.776574</td>\n",
       "      <td>0.800402</td>\n",
       "      <td>0.032345</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.138209</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.026992</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>6</td>\n",
       "      <td>127</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 127, 'n_jo...</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.850788</td>\n",
       "      <td>0.764902</td>\n",
       "      <td>0.824833</td>\n",
       "      <td>0.778279</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.187885</td>\n",
       "      <td>0.024139</td>\n",
       "      <td>0.028382</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>6</td>\n",
       "      <td>147</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 147, 'n_jo...</td>\n",
       "      <td>0.782935</td>\n",
       "      <td>0.849852</td>\n",
       "      <td>0.761436</td>\n",
       "      <td>0.828968</td>\n",
       "      <td>0.781104</td>\n",
       "      <td>0.800859</td>\n",
       "      <td>0.033034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.204018</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.033982</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>6</td>\n",
       "      <td>167</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 167, 'n_jo...</td>\n",
       "      <td>0.786531</td>\n",
       "      <td>0.852170</td>\n",
       "      <td>0.761983</td>\n",
       "      <td>0.830029</td>\n",
       "      <td>0.780384</td>\n",
       "      <td>0.802219</td>\n",
       "      <td>0.033497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.176216</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.036229</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>6</td>\n",
       "      <td>187</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 187, 'n_jo...</td>\n",
       "      <td>0.785086</td>\n",
       "      <td>0.850696</td>\n",
       "      <td>0.763588</td>\n",
       "      <td>0.831391</td>\n",
       "      <td>0.778892</td>\n",
       "      <td>0.801930</td>\n",
       "      <td>0.033258</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.232811</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.038390</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>6</td>\n",
       "      <td>220</td>\n",
       "      <td>-1</td>\n",
       "      <td>42</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 220, 'n_jo...</td>\n",
       "      <td>0.782824</td>\n",
       "      <td>0.852345</td>\n",
       "      <td>0.766158</td>\n",
       "      <td>0.832726</td>\n",
       "      <td>0.774733</td>\n",
       "      <td>0.801757</td>\n",
       "      <td>0.034276</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.039804      0.002139         0.020596        0.018707   \n",
       "1        0.069009      0.003574         0.015993        0.000886   \n",
       "2        0.111984      0.003855         0.019785        0.000742   \n",
       "3        0.139001      0.006956         0.022999        0.001094   \n",
       "4        0.136607      0.005346         0.025994        0.001259   \n",
       "5        0.170410      0.003010         0.029393        0.000801   \n",
       "6        0.202728      0.007050         0.033383        0.002870   \n",
       "7        0.166810      0.002321         0.033990        0.001415   \n",
       "8        0.237019      0.009662         0.038992        0.001670   \n",
       "9        0.039810      0.001328         0.011790        0.000744   \n",
       "10       0.069007      0.002605         0.017586        0.001017   \n",
       "11       0.120407      0.011670         0.020194        0.000747   \n",
       "12       0.137814      0.002308         0.023784        0.000742   \n",
       "13       0.140422      0.002160         0.026389        0.000794   \n",
       "14       0.173627      0.001862         0.028186        0.000402   \n",
       "15       0.211419      0.007542         0.033191        0.001598   \n",
       "16       0.173633      0.002671         0.035592        0.001358   \n",
       "17       0.252068      0.010709         0.041722        0.001692   \n",
       "18       0.040604      0.001618         0.013195        0.000753   \n",
       "19       0.069808      0.002309         0.016593        0.000798   \n",
       "20       0.114324      0.001653         0.020186        0.000396   \n",
       "21       0.139382      0.005413         0.023992        0.000625   \n",
       "22       0.138209      0.002709         0.026992        0.000895   \n",
       "23       0.187885      0.024139         0.028382        0.001195   \n",
       "24       0.204018      0.003624         0.033982        0.001416   \n",
       "25       0.176216      0.008674         0.036229        0.001129   \n",
       "26       0.232811      0.007784         0.038390        0.001851   \n",
       "\n",
       "   param_max_features param_n_estimators param_n_jobs param_random_state  \\\n",
       "0                   3                 20           -1                 42   \n",
       "1                   3                 50           -1                 42   \n",
       "2                   3                 75           -1                 42   \n",
       "3                   3                107           -1                 42   \n",
       "4                   3                127           -1                 42   \n",
       "5                   3                147           -1                 42   \n",
       "6                   3                167           -1                 42   \n",
       "7                   3                187           -1                 42   \n",
       "8                   3                220           -1                 42   \n",
       "9                   5                 20           -1                 42   \n",
       "10                  5                 50           -1                 42   \n",
       "11                  5                 75           -1                 42   \n",
       "12                  5                107           -1                 42   \n",
       "13                  5                127           -1                 42   \n",
       "14                  5                147           -1                 42   \n",
       "15                  5                167           -1                 42   \n",
       "16                  5                187           -1                 42   \n",
       "17                  5                220           -1                 42   \n",
       "18                  6                 20           -1                 42   \n",
       "19                  6                 50           -1                 42   \n",
       "20                  6                 75           -1                 42   \n",
       "21                  6                107           -1                 42   \n",
       "22                  6                127           -1                 42   \n",
       "23                  6                147           -1                 42   \n",
       "24                  6                167           -1                 42   \n",
       "25                  6                187           -1                 42   \n",
       "26                  6                220           -1                 42   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_features': 3, 'n_estimators': 20, 'n_job...           0.759520   \n",
       "1   {'max_features': 3, 'n_estimators': 50, 'n_job...           0.747206   \n",
       "2   {'max_features': 3, 'n_estimators': 75, 'n_job...           0.751464   \n",
       "3   {'max_features': 3, 'n_estimators': 107, 'n_jo...           0.755508   \n",
       "4   {'max_features': 3, 'n_estimators': 127, 'n_jo...           0.756716   \n",
       "5   {'max_features': 3, 'n_estimators': 147, 'n_jo...           0.757940   \n",
       "6   {'max_features': 3, 'n_estimators': 167, 'n_jo...           0.758432   \n",
       "7   {'max_features': 3, 'n_estimators': 187, 'n_jo...           0.758640   \n",
       "8   {'max_features': 3, 'n_estimators': 220, 'n_jo...           0.759408   \n",
       "9   {'max_features': 5, 'n_estimators': 20, 'n_job...           0.755101   \n",
       "10  {'max_features': 5, 'n_estimators': 50, 'n_job...           0.771708   \n",
       "11  {'max_features': 5, 'n_estimators': 75, 'n_job...           0.781878   \n",
       "12  {'max_features': 5, 'n_estimators': 107, 'n_jo...           0.775777   \n",
       "13  {'max_features': 5, 'n_estimators': 127, 'n_jo...           0.771814   \n",
       "14  {'max_features': 5, 'n_estimators': 147, 'n_jo...           0.773096   \n",
       "15  {'max_features': 5, 'n_estimators': 167, 'n_jo...           0.768787   \n",
       "16  {'max_features': 5, 'n_estimators': 187, 'n_jo...           0.767931   \n",
       "17  {'max_features': 5, 'n_estimators': 220, 'n_jo...           0.771868   \n",
       "18  {'max_features': 6, 'n_estimators': 20, 'n_job...           0.802169   \n",
       "19  {'max_features': 6, 'n_estimators': 50, 'n_job...           0.782791   \n",
       "20  {'max_features': 6, 'n_estimators': 75, 'n_job...           0.775715   \n",
       "21  {'max_features': 6, 'n_estimators': 107, 'n_jo...           0.779693   \n",
       "22  {'max_features': 6, 'n_estimators': 127, 'n_jo...           0.781184   \n",
       "23  {'max_features': 6, 'n_estimators': 147, 'n_jo...           0.782935   \n",
       "24  {'max_features': 6, 'n_estimators': 167, 'n_jo...           0.786531   \n",
       "25  {'max_features': 6, 'n_estimators': 187, 'n_jo...           0.785086   \n",
       "26  {'max_features': 6, 'n_estimators': 220, 'n_jo...           0.782824   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.827697           0.768500           0.829069   \n",
       "1            0.830561           0.744601           0.816521   \n",
       "2            0.831765           0.749651           0.815494   \n",
       "3            0.831706           0.746286           0.804759   \n",
       "4            0.832923           0.747744           0.806663   \n",
       "5            0.829023           0.749053           0.805275   \n",
       "6            0.831361           0.746100           0.804111   \n",
       "7            0.831192           0.746991           0.807344   \n",
       "8            0.834705           0.747836           0.810485   \n",
       "9            0.823724           0.735637           0.814792   \n",
       "10           0.842411           0.741675           0.813048   \n",
       "11           0.843712           0.742379           0.815981   \n",
       "12           0.844674           0.749808           0.817724   \n",
       "13           0.841988           0.747462           0.819544   \n",
       "14           0.841828           0.746907           0.820341   \n",
       "15           0.841319           0.751150           0.819941   \n",
       "16           0.842859           0.750304           0.820470   \n",
       "17           0.842996           0.748391           0.821888   \n",
       "18           0.846604           0.762614           0.822268   \n",
       "19           0.846356           0.770091           0.815693   \n",
       "20           0.843925           0.769760           0.823698   \n",
       "21           0.851002           0.768600           0.826142   \n",
       "22           0.850788           0.764902           0.824833   \n",
       "23           0.849852           0.761436           0.828968   \n",
       "24           0.852170           0.761983           0.830029   \n",
       "25           0.850696           0.763588           0.831391   \n",
       "26           0.852345           0.766158           0.832726   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.755201         0.787997        0.033255               18  \n",
       "1            0.760813         0.779941        0.036296               26  \n",
       "2            0.756693         0.781013        0.035250               22  \n",
       "3            0.766386         0.780929        0.032262               23  \n",
       "4            0.766394         0.782088        0.032427               20  \n",
       "5            0.759404         0.780139        0.031339               25  \n",
       "6            0.761363         0.780273        0.032189               24  \n",
       "7            0.763413         0.781516        0.032180               21  \n",
       "8            0.769562         0.784399        0.032841               19  \n",
       "9            0.753147         0.776480        0.035692               27  \n",
       "10           0.780490         0.789866        0.034752               15  \n",
       "11           0.781579         0.793106        0.034399               10  \n",
       "12           0.776350         0.792867        0.033826               11  \n",
       "13           0.766930         0.789548        0.035347               17  \n",
       "14           0.770031         0.790441        0.035064               12  \n",
       "15           0.768206         0.789881        0.034538               14  \n",
       "16           0.767157         0.789744        0.035515               16  \n",
       "17           0.766949         0.790418        0.035822               13  \n",
       "18           0.752982         0.797327        0.035342                9  \n",
       "19           0.777640         0.798514        0.028547                7  \n",
       "20           0.774360         0.797492        0.030401                8  \n",
       "21           0.776574         0.800402        0.032345                5  \n",
       "22           0.778279         0.799997        0.032415                6  \n",
       "23           0.781104         0.800859        0.033034                4  \n",
       "24           0.780384         0.802219        0.033497                1  \n",
       "25           0.778892         0.801930        0.033258                2  \n",
       "26           0.774733         0.801757        0.034276                3  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mejores hiperparámetros: \"+str(model.best_params_))\n",
    "print(\"Mejor Score: \"+str(model.best_score_)+'\\n')\n",
    "\n",
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión del modelo de Random Forest con optimización de hiperparámetros es: 0.8064526851154994\n",
      "La raíz del error cuadrático medio en Train es: 0.004578488921374225\n",
      "La raíz del error cuadrático medio en Test es: 0.026395469456528507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_7 = model.predict(X_train)\n",
    "y_test_pred_7= model.predict(X_test)\n",
    "rmse_train = (mean_squared_log_error(y_train, y_train_pred_7))\n",
    "rmse_test = (mean_squared_log_error(y_test, y_test_pred_7))\n",
    "\n",
    "print('La precisión del modelo de Random Forest con optimización de hiperparámetros es:', model.score (X_test,y_test))\n",
    "\n",
    "print(f'La raíz del error cuadrático medio en Train es: {rmse_train}')\n",
    "print(f'La raíz del error cuadrático medio en Test es: {rmse_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leand\\miniconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=6, n_estimators=187, n_jobs=-1,\n",
       "                      random_state=42)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomf_best = RandomForestRegressor(max_features= 6, n_estimators= 187, n_jobs= -1, random_state= 42)\n",
    "randomf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancia de los predictores en el modelo\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.043490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.042917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.041029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>0.033520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>0.030927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1_x</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>5_y</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>6_x</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3_x</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0_y</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predictor  importancia\n",
       "1    OverallQual     0.043490\n",
       "9      GrLivArea     0.042917\n",
       "6    TotalBsmtSF     0.041029\n",
       "15    GarageArea     0.033520\n",
       "7       1stFlrSF     0.030927\n",
       "..           ...          ...\n",
       "36           1_x     0.000000\n",
       "222          5_y     0.000000\n",
       "230          6_x     0.000000\n",
       "234          3_x     0.000000\n",
       "194          0_y     0.000000\n",
       "\n",
       "[265 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importancia_predictores = pd.DataFrame(\n",
    "                            {'predictor': X_train.columns,\n",
    "                             'importancia': randomf_best.feature_importances_}\n",
    "                            )\n",
    "print(\"Importancia de los predictores en el modelo\")\n",
    "print(\"-------------------------------------------\")\n",
    "importancia_predictores.sort_values('importancia', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobaremos la performance de una regresión lineal con atributos polinómicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b0261dadc93494a3555537365c322d83416c4a1ed03d5df7c77bc94b07686c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
